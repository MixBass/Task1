<?xml version='1.0' encoding='UTF-8'?>
<doc><link auto="true" type="str" verify="true">https://overclockers.ru/itnews/show/100341/nvidia-predstavlyaet-masshtabiruemyj-gpu-uskorennyj-superkompjuter-v-oblake-microsoft-azure</link><category verify="true" type="str" auto="true"><![CDATA[Новости IT-рынка]]></category><date verify="true" type="str" auto="true"><![CDATA[19 ноября 2019, вторник 09:16]]></date><title verify="true" type="str" auto="true"><![CDATA[NVIDIA представляет масштабируемый GPU-ускоренный суперкомпьютер в облаке Microsoft Azure]]></title><author verify="true" type="str" auto="true"><![CDATA[admin]]></author><text verify="true" type="str" auto="true"><![CDATA[  ДЕНВЕР—SC19— 18 ноября 2019—NVIDIA сегодня анонсировала доступность нового типа GPU-ускоренного суперкомпьютера в облаке Microsoft Azure.

Предназначенные для самых сложных ИИ- и высокопроизводительных (HPC) вычислений новейшие системы на базе нового инстанса Azure NDv2 входят в число самых мощных суперкомпьютеров мира и позволяют объединять до 800 GPU NVIDIA с тензорными ядрами V100 через единую сеть Mellanox InfiniBand. Таким образом, пользователи впервые смогут арендовать целый ИИ-суперкомпьютер прямо на своем рабочем месте и сопоставить его возможности с возможностями громоздких локальных суперкомпьютеров, на сборку которых уходят месяцы.



“До сегодняшнего дня суперкомпьютеры для ИИ и HPC были доступны только для больших организаций, - говорит Ян Бак (Ian Buck), вице-президент и директор по ускоренным вычислениям в NVIDIA. - Новое предложение Microsoft Azure демократизирует ИИ, предоставляя широкий доступ к ключевому инструменту для решения важнейших глобальных задач”.

Гириш Баблани (Girish Bablani), корпоративный вице-президент Azure Compute в Microsoft, добавил: “По мере развития облачных вычислений клиенты ищут все более мощные сервисы. В сотрудничестве с NVIDIA компания Microsoft предоставляет своим клиентам такой уровень вычислений, о котором раньше невозможно были и мечтать, открывая дверь в мир инноваций”.

Колоссальная производительность, экономическая выгода

Новое решение, идеальное для сложных ИИ-вычислений, машинного обучения и HPC-задач, предлагает значительно более высокую производительность по выгодной цене по сравнению с традиционными решениями на базе CPU. Исследователи могут быстро развернуть несколько NDv2 инстансов и обучить сложные диалоговые ИИ-модели всего за несколько часов.

Так, инженеры Microsoft и NVIDIA с помощью 64 NDv2 инстансов на предрелизной версии кластера обучили BERT – популярную диалоговую ИИ-модель - всего за три часа. Частично это было достигнуто благодаря мульти-GPU оптимизациям, полученных с помощью NCCL, библиотеки NVIDIA CUDA X™ и высокоскоростных интерфейсов Mellanox.

Пользователи также ощутят преимущества использования нескольких NDv2 инстансов при выполнении сложных HPC-вычислений, например, в LAMMPS – популярном приложении молекулярной динамики, которое используется для моделирования материалов на уровне атомов в таких областях, как создание лекарств. Всего лишь один NDv2 инстанс обеспечивает производительность на порядок выше по сравнению с традиционным HPC-узлом без GPU-ускорения в приложениях такого типа, как глубокого обучение. При этом производительность можно линейно увеличивать, объединяя сотни инстансов, для масштабного моделирования.

Все NDv2 инстансы оптимизированы для GPU-ускоренных HPC приложений, ПО для машинного обучения и фреймворков глубокого обучения, таких как TensorFlow, PyTorch и MxNet из репозитария контейнеров NVIDIA NGC и Azure Marketplace. Репозитарий также поддерживает пакеты Helm для установки ИИ-программ на кластерах Kubernetes.

Доступность и цены

NDv2 уже доступны в режиме предварительного просмотра. Инстансы с восьмью GPU NVIDIA V100 можно объединять в кластеры. Подробнее смотрите здесь.
]]></text></doc>