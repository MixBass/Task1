<?xml version='1.0' encoding='UTF-8'?>
<doc><link auto="true" type="str" verify="true">https://overclockers.ru/itnews/show/100340/nvidia-predstavlyaet-po-magnum-io-dlya-optimizacii-uzkih-mest-pri-rabote-s-dannymi-v-prilozheniyah-ii-i-hpc</link><category verify="true" type="str" auto="true"><![CDATA[Новости IT-рынка]]></category><date verify="true" type="str" auto="true"><![CDATA[19 ноября 2019, вторник 09:10]]></date><title verify="true" type="str" auto="true"><![CDATA[NVIDIA представляет ПО Magnum IO для оптимизации узких мест при работе с данными в приложениях ИИ и HPC]]></title><author verify="true" type="str" auto="true"><![CDATA[admin]]></author><text verify="true" type="str" auto="true"><![CDATA[  ДЕНВЕР—SC19 — 18 ноября 2019—NVIDIA сегодня представила набор программного обеспечения NVIDIA Magnum IO, позволяющее исследователям в области ИИ и HPC обрабатывать большие объемы данных за считанные минуты вместо нескольких часов.

ПО Magnum IO устраняет узкие места при хранении и передаче данных, ускоряя до 20 раз обработку массивов данных в многосерверных мульти-GPU вычислительных узлах и позволяя быстро выполнять финансовый анализ, моделирование климата и другие HPC-задачи.



NVIDIA разработала Magnum IO в сотрудничестве с лидерами индустрии в сегменте передачи и хранения данных, включая DataDirect Networks, Excelero, IBM, Mellanox и WekaIO.

“В основе всего того, что связано с ИИ, находится обработка больших объемов собранных или смоделированных данных, - говорит Дженсен Хуанг (Jensen Huang), учредитель и генеральный директор NVIDIA. - По мере экспоненциального увеличения объемов и скорости поступления данных их обработка становится одной из самых важных, но и крайне затратных задач для ЦОД.”

“Для экстремальных вычислений нужны экстремально быстрые интерфейсы. Именно это и обеспечивает ПО Magnum IO, применяя GPU-ускорение, кардинально изменившее вычисления, к передаче и хранению данных. Исследователям больше не придется долго ожидать окончания обработки данных. Теперь они смогут сконцентрироваться на сути своей работы”, - добавил Дженсен.

В основе ПО Magnum IO лежит технология GPUDirect, позволяющая данным обходить CPU и перемещаться по магистралям, созданным графическими процессорами, накопителями и сетевыми устройствами. GPUDirect совместима с широким спектром интерфейсов и API, включая NVIDIA NVLink™ и NCCL, а также OpenMPI и UCX, и состоит из одноранговых (peer-to-peer) и RDMA элементов.

Новейшим элементом является GPUDirect Storage, позволяющий исследователям в обход CPU получать доступ к хранимым файлам для моделирования, анализа и визуализации.

ПО NVIDIA Magnum IO уже доступно, за исключением GPUDirect Storage, к которому пока только открыт ранний доступ. Широкая доступность GPUDirect Storage запланирована на первое полугодие 2020 года.
]]></text></doc>