<?xml version='1.0' encoding='UTF-8'?>
<doc><link auto="true" type="str" verify="true">https://overclockers.ru/itnews/show/103344/novyj-gpu-nvidia-na-arhitekture-ampere-dlya-data-centrov-uzhe-v-proizvodstve</link><category verify="true" type="str" auto="true"><![CDATA[Новости IT-рынка]]></category><date verify="true" type="str" auto="true"><![CDATA[15 мая 2020, пятница 09:33]]></date><title verify="true" type="str" auto="true"><![CDATA[Новый GPU NVIDIA на архитектуре Ampere для дата-центров уже в производстве]]></title><author verify="true" type="str" auto="true"><![CDATA[admin]]></author><text verify="true" type="str" auto="true"><![CDATA[  14 мая 2020 NVIDIA объявила о начале производства и поставок первого графического процессора на базе архитектуре NVIDIA® Ampere - NVIDIA A100.



Благодаря передовой архитектуре NVIDIA Ampere графический процессор A100 обладает максимальным приростом производительности среди всех восьми поколений GPU NVIDIA и создает единую платформу для обучения ИИ и инференса, ускоряя производительность до 20 раз по сравнению с предшественниками. Универсальный ускоритель A100 также предназначен для задач анализа данных, научных вычислений и облачной графики.

«Стремительное распространение облачных вычислений и ИИ кардинально меняет архитектуру дата-центров: CPU-серверы сегодня уступают место GPU-ускоренным вычислениям, - говорит Дженсен Хуанг (Jensen Huang), основатель и генеральный директор NVIDIA. - Графические процессоры NVIDIA A100 в 20 раз быстрее в ИИ-задачах и ускоряют машинное обучение на всех этапах – от анализа данных до обучения и инференса. Впервые вертикально и горизонтально масштабируемые задачи можно ускорять на одной платформе. NVIDIA A100 одновременно увеличивает полосу пропускания и снижает стоимость дата-центров».

Новые адаптивные вычислительное технологии в A100 позволяют подобрать необходимую вычислительную мощь для каждой задачи. Каждый GPU A100 может быть разделен на максимум семь независимых инстансов для задач инференса, а благодаря интерконнекту третьего поколения NVIDIA NVLink® графические процессоры A100 можно объединить в один гигантский GPU для работы с моделями большого объёма и для работы с масштабными задачами.

Ожидается, что процессоры A100 интегрируют в свои решения следующие поставщики облачных услуг и сборщики систем: Alibaba Cloud, Amazon Web Services (AWS), Atos, Baidu Cloud, Cisco, Dell Technologies, Fujitsu, GIGABYTE, Google Cloud, H3C, Hewlett Packard Enterprise (HPE), Inspur, Lenovo, Microsoft Azure, Oracle, Quanta/QCT, Supermicro и Tencent Cloud.

Широкое применение

Компания Microsoft одной из первых приобрела графические процессоры NVIDIA A100, чтобы задействовать их преимущества в производительности и масштабируемости для задач, связанных с обработкой языка, речи, компьютерного зрения, мультимодальности и не только.

DoorDash, платформа доставки еды по требованию, служащая жизненной артерией для ресторанов во время пандемии, отмечает, что наличие гибкой ИИ-инфраструктуры является важным фактором для возможности масштабировать бизнес, одновременно повышая его эффективность и снижая издержки.

Процессоры A100 также будут использоваться в суперкомпьютерах нового поколения следующих лабораторий и исследовательских организаций: Университета Индианы (США), Юлихского исследовательского центра (Германия), Технологического Института Карлсруэ (Германия), Общества Макса Планка (Max Planck Computing and Data Facility, Германия), Научно-исследовательского вычислительного центра Министерства энергетики США в Национальной лаборатории Лоуренса в Беркли.

Пять инноваций A100

Вычислительные возможности GPU NVIDIA A100 стали возможны благодаря пяти ключевым инновациям:
Архитектура Ampere — в основе GPU A100 лежит новая архитектура NVIDIA Ampere с более чем 54 млрд транзисторов, что делает его крупнейшим в мире 7-нм процессором.
Тензорные ядра третьего поколения с TF32 — получившие широкое применение тензорные ядра NVIDIA стали еще более гибкими, быстрыми и простыми в использовании. Теперь они поддерживают TF32 для ИИ, что поднимает скорость ИИ-вычислений до 20 раз для FP32 без каких-либо изменений кода. Также, тензорные ядра теперь поддерживают FP64, что повышает скорость работы в HPC-приложениях до 2.5 раз по сравнению с предыдущим поколением.
Multi-instance GPU (MIG) позволяет разделить A100 на максимум семь отдельных GPU для выполнения задач разной степени сложности для оптимизации использования GPU и эффективности инвестиций.
NVIDIA NVLink третьего поколения — удваивает скорость высокоскоростного соединения между GPU для более эффективного масштабирования вычислений.
Structural sparsity — технология удваивает производительность, используя разреженность данных в задачах ИИ.
Вместе эти возможности превращают NVIDIA A100 в идеальное решение для разнообразных требовательных задач, включая обучение нейросетей и инференс, научное моделирование, диалоговый ИИ, рекомендательные системы, геномику, анализ данных, сейсмическое моделирование и финансовое прогнозирование.

NVIDIA A100 доступен в новых системах, скоро в облаке

Анонсированная сегодня система NVIDIA DGX A100™ включает восемь GPU NVIDIA A100, связанных интерфейсом NVIDIA NVLink. Система уже доступна у NVIDIA и будет доступна у партнеров компании.



Сервисы на базе A100 планируют предоставлять Alibaba Cloud, AWS, Baidu Cloud, Google Cloud, Microsoft Azure, Oracle и Tencent Cloud.

Ожидается широкая линейка серверов на базе A100 от ведущих производителей, включая Atos, Dell Technologies, Fujitsu, GIGABYTE, H3C, HPE, Inspur, Lenovo, Quanta/QCT и Supermicro.

Чтобы ускорить разработку серверов, NVIDIA создала референсный дизайн модулей HGX A100 в форме интегрируемых плат с различными конфигурациями GPU.

Соединение 4-х GPU в модулях HGX A100 обеспечивает технология NVLink. В модулях же с восьмью GPU взаимодействие GPU-to-GPU происходит через NVIDIA NVSwitch™. Благодаря новой технологии MIG, модуль HGX A100 можно разбить на 56 отдельных GPU, каждый из которых будет быстрее NVIDIA T4. Общая производительность сервера с восьмью GPU на борту в ИИ-вычислениях составляет 10 петафлопс.



Программные оптимизации NVIDIA в A100

NVIDIA также анонсировала несколько обновлений своего программного стека, включая новые версии более чем 50 библиотек CUDA-X, используемых для ускорения графики, моделирования и ИИ; для CUDA 11; для NVIDIA Jarvis, мультимодального фреймворка для диалоговых ИИ-сервисов; для NVIDIA Merlin, фреймворка для рекомендательных систем; и NVIDIA HPC SDK, который включает компиляторы, библиотеки и инструменты, помогающие HPC-разработчикам отлаживать и оптимизировать свой код для A100.
]]></text></doc>