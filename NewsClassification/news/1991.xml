<?xml version='1.0' encoding='UTF-8'?>
<doc><link auto="true" type="str" verify="true">https://overclockers.ru/itnews/show/90450/nvidia-obespechivaet-podderzhku-inferensa-glubokogo-obucheniya-v-gipermasshtabiruemyh-data-centrah</link><category verify="true" type="str" auto="true"><![CDATA[Новости IT-рынка]]></category><date verify="true" type="str" auto="true"><![CDATA[28 марта 2018, среда 15:03]]></date><title verify="true" type="str" auto="true"><![CDATA[NVIDIA обеспечивает поддержку инференса глубокого обучения в гипермасштабируемых дата-центрах]]></title><author verify="true" type="str" auto="true"><![CDATA[admin]]></author><text verify="true" type="str" auto="true"><![CDATA[  САН-ХОСЕ, Калифорния— Конференция GTC —27 марта 2018—NVIDIA анонсировала ряд новых технологий и партнерств, которые расширяют потенциальный рынок инференса до 30 млн гипермасштабируемых серверов во всем мире и значительно сокращают стоимость сервисов и приложений глубокого обучения.

Выступая с речью на конференции GTC 2018, президент NVIDIA Дженсен Хуанг (Jensen Huang) рассказал о применении GPU-ускорения для инференса глубокого обучения в таких областях, как распознавание речи, обработка естественного языка, системы рекомендаций и распознавание изображений, в дата-центрах и автомобилях, а также в таких устройствах, как роботы и дроны.

NVIDIA анонсировала новую версию ПО для инференса TensorRT и интеграцию TensorRT в популярный фреймворк Google TensorFlow. NVIDIA также объявила о том, что Kaldi, самый популярный фреймворк для распознавания речи, оптимизирован для GPU. Тесное сотрудничество NVIDIA с партнерами, такими, как Amazon, Facebook и Microsoft, позволяет разработчикам применять GPU-ускорение при использовании ONNX и WinML.

“GPU-ускорение для инференса глубокого обучения позволяет крупнейшим нейросетям работать в реальном времени при минимальных затратах, - говорит Ян Бак (Ian Buck), вице-президент и директор по ускоренным вычислениям в NVIDIA. - Со все более широкой поддержкой умных приложений и фреймворков теперь мы можем улучшить качество глубокого обучения и помочь сократить стоимость для 30 миллионов гипермасштабируемых серверов”.

TensorRT, интеграция в TensorFlow

NVIDIA представила ПО TensorRT 4 для ускорения инференса глубокого обучения в широком спектре приложений. TensorRT обеспечивает высокую точность работы сетей с операциями INT8 и FP16, что поможет сократить серверные затраты до 70%. (1)

TensorRT 4 может использоваться для быстрой оптимизации, проверки и развертывания обученных нейросетей в гипермасштабируемых дата-центрах, встраиваемых и GPU платформах. Программное обеспечение ускоряет инференс до 190 раз (2) по сравнению с CPU в приложениях для компьютерного зрения, машинного перевода, автоматического распознавания речи, синтеза речи и др.

Для еще большего упрощения процесса инженеры NVIDIA и Google интегрировали TensorRT в TensorFlow 1.7, чтобы улучшить работу приложений инференса на GPU.

Райат Монга (Rajat Monga), главный инженер в Google, отмечает: “Команда TensorFlow тесно работает с NVIDIA, чтобы сообщество глубокого обучения получило максимальную производительность, возможную на графических процессорах NVIDIA. Интеграция NVIDIA TensorRT в TensorFlow повышает скорость инференса до 8 раз (в сравнении с обычным исполнением на GPU при низких задержках) на платформах глубокого обучения NVIDIA с технологией Volta Tensor Core, что позволяет получить высочайшую скорость инференса с GPU в рамках TensorFlow”.

NVIDIA оптимизировала ведущий в мире речевой фреймворк Kaldi, чтобы повысить производительность на GPU. GPU-ускорение позволит создавать более точных и полезных виртуальных помощников для потребителей и сократить расходы на внедрение для операторов дата-центров.

Инференс для дата-центров

Владельцам дата-центров все время приходится искать баланс между производительностью и эффективностью, чтобы их серверы работали максимально продуктивно. Серверы на базе GPU NVIDIA Tesla могут заменить несколько стоек CPU-серверов для приложений инференса, освобождая ценное место в серверной и уменьшая расходы на питание и охлаждение.

Инференс для самоуправляемых автомобилей

TensorRT можно также установить в автономных автомобилях NVIDIA DRIVE и встраиваемых платформах NVIDIA Jetson. Глубокие нейросети на каждом фреймворке можно обучить в системах NVIDIA DGX™ в дата-центре и затем внедрять во все типы устройств – от роботов до самоуправляемых автомобилей – для осуществления на них инференса в реальном времени.

С помощью TensorRT разработчики могут сосредоточиться на разработке новых приложений глубокого обучения, а не тратить время на оптимизацию производительности при внедрении инференса. Разработчики могут получить молниеносный инференс с помощью TensorRT в операциях INT8 и FP16 при значительно более низкой латентности. Это критически важно в таких областях, как обнаружение объектов и планирование маршрута на встраиваемых и автомобильных платформах.

Участники программы NVIDIA для разработчиков могут узнать больше о TensorRT 4 на странице https://developer.nvidia.com/tensorrt.

(1) Общая стоимость владения с учетом смешанной нагрузки от крупного провайдера облачного сервиса: 60% нейронной совместной фильтрации (NCF), 20% нейронного машинного перевода (NMT), 15% автоматического распознавания речи (ASR), 5% компьютерного зрения (CV), на сокет (Tesla V100 GPU vs CPU), ускорение работы: 10x NCF, 20x NMT, 15x ASR, 40x CV. Конфигурация CPU-узла: двухсокетный Intel Skylake 6130. Рекомендуемая конфигурация GPU-узла: восемь Volta HGX-1.
(2) Прирост производительности в спектре важных случаев. Пример: скорость инференса ResNet50 v1 при 7-мс латентности в 190 раз выше с TensorRT на GPU Tesla V100, чем на TensorFlow на односокетном Intel Skylake 6140 при минимальной латентности (пакет = 1).

О компании NVIDIA

NVIDIA (NASDAQ: NVDA) находится на вершине искусства и науки визуальных вычислений с 1993 года. Технологии компании превращают мир изображений в мир интерактивных открытий для самых разных пользователей — геймеров и ученых, пользователей мобильных устройств, офисных работников и не только. Подробнее смотрите на сайтах http://www.nvidia.ru, http://nvidianews.nvidia.com и http://blogs.nvidia.com.

Отдельные заявления данного пресс-релиза, включая преимущества, результаты и цели партнерства NVIDIA и Continental; преимущества и возможности NVIDIA DRIVE и Xavier, технологии Continental и ИИ, возможность вывода на рынок технологий автономного вождения; и ожидаемые продажи Continental в 2020, приводятся с расчетом на будущее и могут изменяться в результате обстоятельств и рисков, приводящих к результатам, материально отличным от ожидаемых. Такие обстоятельства и риски включают разработку более быстрой или эффективной технологии, использование CPU для параллельных вычислений, конструкторские, производственные или программные ошибки, влияние технологического развития и конкуренции, изменения в предпочтениях и требованиях покупателей, выбор других стандартов или продуктов конкурентов покупателями, изменения в стандартах отрасли и интерфейсах, неожиданное снижение производительности наших продуктов или технологий при интеграции в системы, а также другие риски, указываемые время от времени в отчетах, которые NVIDIA отсылает в Комиссию по ценным бумагам и биржевым операциям, включая отчет по форме 10-Q за финансовый период, закончившийся 29 октября 2017 года. Копии отчетов для SEC опубликованы на нашем сайте и доступны у NVIDIA бесплатно. Данные, относящиеся к будущему заявлению, не относятся к будущей производительности, а только к текущему моменту, и, кроме случаев, установленных законом, NVIDIA не несет ответственность за обновление таких заявлений, чтобы отразить будущие события или обстоятельства.

© 2018 NVIDIA Corporation. Все права защищены. NVIDIA, логотип NVIDIA, NVIDIA DRIVE и Xavier являются товарными знаками и/или зарегистрированными товарными знаками компании NVIDIA в США и/или других странах. Все другие названия компаний и/или продуктов могут являться товарными знаками и/или зарегистрированными товарными знаками соответствующих владельцев. Функции, цены, наличие и спецификации могут быть изменены без предупреждения.
]]></text></doc>