<?xml version='1.0' encoding='UTF-8'?>
<doc><link auto="false" type="str" verify="true"></link><category verify="true" type="str" auto="false"><![CDATA[Новости IT-рынка]]></category><date verify="true" type="str" auto="false"><![CDATA[]]></date><title verify="true" type="str" auto="false"><![CDATA[Новости IT-рынка]]></title><author verify="true" type="str" auto="false"><![CDATA[]]></author><text verify="true" type="str" auto="false"><![CDATA[   денвер — sc19  —  18   ноябрь   2019 — nvidia   сегодня   представлять   набор   программный   обеспечение   nvidia   magnum   io ,  позволять   исследователь   в   область   ия   и   hpc   обрабатывать   большой   объем   данные   за   считать   минута   вместо   несколько   часы . 
 
 по   magnum   io   устранять   узкий   место   при   хранение   и   передача   данные ,  ускорять   до   20   раз   обработка   массив   данные   в   многосерверный   мультя - gpu   вычислительный   узел   и   позволять   быстро   выполнять   финансовый   анализ ,  моделирование   климат   и   другой   hpc - задача . 
 
 
 
 nvidia   разрабатывать   magnum   io   в   сотрудничество   с   лидер   индустрия   в   сегмент   передача   и   хранение   данные ,  включая   datadirect   networks ,  excelero ,  ibm ,  mellanox   и   wekaio . 
 
 “ в   основа   все   то ,  что   связывать   с   ия ,  находиться   обработка   большой   объем   собирать   или   смоделировать   данные , -  говорить   дженсен   хуанг  ( jensen   huang ),  учредитель   и   генеральный   директор   nvidia .  -  по   мера   экспоненциальный   увеличение   объем   и   скорость   поступление   данные   их   обработка   становиться   один   из   самый   важный ,  но   и   крайне   затратный   задача   для   цод . ”
 
 “ для   экстремальный   вычисление   нужный   экстремально   быстрый   интерфейс .   именно   это   и   обеспечивать   по   magnum   io ,  применять   gpu - ускорение ,  кардинальный   изменять   вычисление ,  к   передача   и   хранение   данный .   исследователь   больше   не   приходиться   долго   ожидать   окончание   обработка   данные .   теперь   они   смочь   сконцентрироваться   на   суть   свой   работа ”, -  добавлять   дженсен . 
 
 в   основа   по   magnum   io   лежать   технология   gpudirect ,  позволять   данные   обходить   cpu   и   перемещаться   по   магистраль ,  создавать   графический   процессор ,  накопитель   и   сетевой   устройство .   gpudirect   совместимый   с   широкий   спектр   интерфейс   и   api ,  включая   nvidia   nvlink ™   и   nccl ,  а   также   openmpi   и   ucx ,  и   состоять   из   одноранговый  ( peer - to - peer )  и   rdma   элемент . 
 
 новый   элемент   являться   gpudirect   storage ,  позволять   исследователь   в   обход   cpu   получать   доступ   к   хранить   файл   для   моделирование ,  анализ   и   визуализация . 
 
 по   nvidia   magnum   io   уже   доступно ,  за   исключение   gpudirect   storage ,  к   который   пока   только   открывать   ранний   доступ .   широкий   доступность   gpudirect   storage   запланировать   на   первый   полугодие   2020   год . 
]]></text></doc>